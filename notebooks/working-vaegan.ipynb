{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# img_directory = '/Users/rwilliams/Desktop/celeba/training'\n",
    "img_directory = '/home/ec2-user/training-data/img_align_celeba'\n",
    "model_save_path = '/home/ec2-user/tf-checkpoints/vaegan-celeba/checkpoint.ckpt'\n",
    "outputs_directory = '/home/ec2-user/outputs/vaegan-celeba'\n",
    "log_directory = '/home/ec2-user/tf-logs/vaegan-celeba'\n",
    "\n",
    "batch_size = 64\n",
    "training_set_size = 512\n",
    "img_size = 64\n",
    "learning_rate = 0.0003\n",
    "zsize = 128\n",
    "\n",
    "# weights similarity loss term for decoder loss\n",
    "# loss_gamma = 1e-2\n",
    "# trying higher gamma\n",
    "# loss_gamma = 1e-2\n",
    "loss_gamma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jupyter imports\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "from utils import imshow, resize_crop, load_img, pixels01, pixels11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.conda/envs/keras/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "training = np.array([resize_crop(load_img(i+1, img_directory), (img_size, img_size)) for i in range(training_set_size)])\n",
    "# rescale each pixel to [-1, 1]. Supposed to help with GANs\n",
    "training = pixels11(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create models\n",
    "\n",
    "import tensorflow as tf\n",
    "from autoencoder import Autoencoder\n",
    "from discriminator import Discriminator\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42.0)\n",
    "\n",
    "# input images feed\n",
    "X = tf.placeholder(tf.float32, [None, img_size, img_size, 3])\n",
    "\n",
    "# for feeding random draws of z (latent variable)\n",
    "Z = tf.placeholder(tf.float32, [None, zsize])\n",
    "\n",
    "# flags to pass to networks to set batch normalization layers\n",
    "# as trainable or not\n",
    "encoder_batch_trainable = tf.placeholder(tf.bool)\n",
    "decoder_batch_trainable = tf.placeholder(tf.bool)\n",
    "disc_batch_trainable = tf.placeholder(tf.bool)\n",
    "\n",
    "# encoder, decoder that will be connected to a discriminator\n",
    "vae = Autoencoder(img_shape=(img_size, img_size, 3), zsize=zsize)\n",
    "encoder = vae.encoder(X, encoder_batch_trainable)\n",
    "decoder = vae.decoder(encoder, decoder_batch_trainable)\n",
    "\n",
    "# a second decoder for decoding samplings of z\n",
    "# decoder_z_obj = Autoencoder(img_shape=(img_size, img_size, 3), zsize=zsize)\n",
    "# decoder_z = decoder_z_obj.decoder(Z, decoder_batch_trainable, reuse=True)\n",
    "\n",
    "# discriminator attached to vae output\n",
    "disc_vae_obj = Discriminator(img_shape=(img_size, img_size, 3))\n",
    "disc_vae_obj.disc(decoder, disc_batch_trainable)\n",
    "disc_vae_logits = disc_vae_obj.logits\n",
    "\n",
    "# discriminator attached to X input\n",
    "# shares weights with other discriminator\n",
    "disc_x_obj = Discriminator(img_shape=(img_size, img_size, 3))\n",
    "disc_x_obj.disc(X, disc_batch_trainable, reuse=True)\n",
    "disc_x_logits = disc_x_obj.logits\n",
    "\n",
    "# discriminator attached to random Zs passed through decoder\n",
    "# shares weights with other discriminator\n",
    "# disc_z_obj = Discriminator(img_shape=(img_size, img_size, 3))\n",
    "# disc_z_obj.disc(decoder_z, disc_batch_trainable, reuse=True)\n",
    "# disc_z_logits = disc_z_obj.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up loss functions and training_ops\n",
    "\n",
    "# latent loss used for training encoder\n",
    "latent_loss = vae.latent_loss()\n",
    "\n",
    "# loss that uses decoder to determine similarity between\n",
    "# actual input images and output images from the vae\n",
    "similarity_xentropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=disc_x_obj.similarity, \n",
    "    logits=disc_vae_obj.similarity)\n",
    "similarity_loss = tf.reduce_mean(similarity_xentropy)\n",
    "\n",
    "# losses for the discriminator's output. Labels are real: 0, fake: 1.\n",
    "# cross entropy with 1 labels, since training prob that image is fake\n",
    "disc_vae_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=tf.ones_like(disc_vae_logits),\n",
    "    logits=disc_vae_logits))\n",
    "\n",
    "# cross entropy with 0 labels, since training prob that image is fake\n",
    "disc_x_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=tf.zeros_like(disc_x_logits),\n",
    "    logits=disc_x_logits))\n",
    "\n",
    "# cross entropy with 1 labels, since training prob that image is fake\n",
    "# disc_z_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#     labels=tf.ones_like(disc_z_logits),\n",
    "#     logits=disc_z_logits))\n",
    "\n",
    "# minimize these with optimizer\n",
    "# disc_loss = disc_vae_loss + disc_x_loss + disc_z_loss\n",
    "disc_loss = disc_vae_loss + disc_x_loss\n",
    "encoder_loss = latent_loss + similarity_loss\n",
    "decoder_loss = loss_gamma * similarity_loss - disc_loss\n",
    "\n",
    "# get weights to train for each of encoder, decoder, etc.\n",
    "# pass this to optimizer so it only trains w.r.t the network\n",
    "# we want to train and just uses other parts of the network as is\n",
    "# (for example use the discriminator to compute a loss during training\n",
    "# of the encoder, but don't adjust weights of the discriminator)\n",
    "\n",
    "encoder_vars = [i for i in tf.trainable_variables() if 'encoder' in i.name]\n",
    "decoder_vars = [i for i in tf.trainable_variables() if 'decoder' in i.name]\n",
    "disc_vars = [i for i in tf.trainable_variables() if 'discriminator' in i.name]\n",
    "\n",
    "encoder_update_ops = [i for i in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'encoder' in i.name]\n",
    "decoder_update_ops = [i for i in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'decoder' in i.name]\n",
    "disc_update_ops = [i for i in tf.get_collection(tf.GraphKeys.UPDATE_OPS) if 'discriminator' in i.name]\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    \n",
    "with tf.control_dependencies(encoder_update_ops):\n",
    "    train_encoder = optimizer.minimize(encoder_loss, var_list=encoder_vars)\n",
    "    \n",
    "with tf.control_dependencies(decoder_update_ops):\n",
    "    train_decoder = optimizer.minimize(decoder_loss, var_list=decoder_vars)\n",
    "\n",
    "with tf.control_dependencies(disc_update_ops):\n",
    "    train_disc = optimizer.minimize(disc_loss, var_list=disc_vars)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to restore session\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/tf-checkpoints/vaegan-celeba/checkpoint.ckpt\n",
      "failed to restore session, creating a new one\n"
     ]
    }
   ],
   "source": [
    "# create or restore session\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "try:\n",
    "    print('trying to restore session')\n",
    "    saver.restore(sess, model_save_path)\n",
    "    print('restored session')\n",
    "except:\n",
    "    print('failed to restore session, creating a new one')\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "# write logs for tensorboard\n",
    "writer = tf.summary.FileWriter(log_directory, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data for tensorboard\n",
    "\n",
    "disc_vae_out = tf.reduce_mean(tf.sigmoid(disc_vae_logits))\n",
    "disc_x_out = tf.reduce_mean(tf.sigmoid(disc_x_logits))\n",
    "# disc_z_out = tf.reduce_mean(tf.sigmoid(disc_z_logits))\n",
    "\n",
    "tf.summary.scalar('encoder_loss', encoder_loss)\n",
    "tf.summary.scalar('decoder_loss', decoder_loss)\n",
    "tf.summary.scalar('discriminator_loss', disc_loss)\n",
    "tf.summary.scalar('similarity_loss', similarity_loss)\n",
    "tf.summary.scalar('disc_vae_loss', disc_vae_loss)\n",
    "tf.summary.scalar('disc_x_loss', disc_x_loss)\n",
    "# tf.summary.scalar('disc_z_loss', disc_z_loss)\n",
    "tf.summary.scalar('latent_loss', latent_loss)\n",
    "\n",
    "tf.summary.scalar('disc_vae_out', disc_vae_out)\n",
    "tf.summary.scalar('disc_x_out', disc_x_out)\n",
    "# tf.summary.scalar('disc_z_out', disc_z_out)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 ........................\n",
      "saving session\n",
      "epoch 1 ........................\n",
      "saving session\n",
      "epoch 2 ........................\n",
      "saving session\n",
      "epoch 3 ........................\n",
      "saving session\n",
      "epoch 4 ........................\n",
      "saving session\n",
      "epoch 5 ........................\n",
      "saving session\n",
      "epoch 6 ........................\n",
      "saving session\n",
      "epoch 7 ........................\n",
      "saving session\n",
      "epoch 8 ........................\n",
      "saving session\n",
      "epoch 9 ........................\n",
      "saving session\n",
      "epoch 10 ........................\n",
      "saving session\n",
      "epoch 11 ........................\n",
      "saving session\n",
      "epoch 12 ........................\n",
      "saving session\n",
      "epoch 13 ........................\n",
      "saving session\n",
      "epoch 14 ........................\n",
      "saving session\n",
      "epoch 15 ........................\n",
      "saving session\n",
      "epoch 16 ........................\n",
      "saving session\n",
      "epoch 17 ........................\n",
      "saving session\n",
      "epoch 18 ........................\n",
      "saving session\n",
      "epoch 19 ........................\n",
      "saving session\n",
      "epoch 20 ........................\n",
      "saving session\n",
      "epoch 21 ........................\n",
      "saving session\n",
      "epoch 22 ........................\n",
      "saving session\n",
      "epoch 23 ........................\n",
      "saving session\n",
      "epoch 24 ........................\n",
      "saving session\n",
      "epoch 25 ........................\n",
      "saving session\n",
      "epoch 26 ........................\n",
      "saving session\n",
      "epoch 27 ........................\n",
      "saving session\n",
      "epoch 28 ........................\n",
      "saving session\n",
      "epoch 29 ........................\n",
      "saving session\n",
      "epoch 30 ........................\n",
      "saving session\n",
      "epoch 31 ........................\n",
      "saving session\n",
      "epoch 32 ........................\n",
      "saving session\n",
      "epoch 33 ........................\n",
      "saving session\n",
      "epoch 34 ........................\n",
      "saving session\n",
      "epoch 35 ........................\n",
      "saving session\n",
      "epoch 36 ........................\n",
      "saving session\n",
      "epoch 37 ........................\n",
      "saving session\n",
      "epoch 38 ........................\n",
      "saving session\n",
      "epoch 39 ........................\n",
      "saving session\n",
      "epoch 40 ........................\n",
      "saving session\n",
      "epoch 41 ........................\n",
      "saving session\n",
      "epoch 42 ........................\n",
      "saving session\n",
      "epoch 43 ........................\n",
      "saving session\n",
      "epoch 44 ........................\n",
      "saving session\n",
      "epoch 45 ........................\n",
      "saving session\n",
      "epoch 46 ........................\n",
      "saving session\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "epochs = 10000\n",
    "batches = int(float(training_set_size) / batch_size)\n",
    "do_train = {\n",
    "    'encoder': True,\n",
    "    'decoder': True,\n",
    "    'disc':    True\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print ('epoch %s ' % epoch, end='')\n",
    "    zdraws = np.random.normal(size=(training_set_size, zsize))\n",
    "    \n",
    "    # train discriminator\n",
    "    if do_train['disc']:\n",
    "        for batch in range(batches):\n",
    "            xfeed = training[batch*batch_size:(batch+1)*batch_size]\n",
    "            zfeed = zdraws[batch*batch_size:(batch+1)*batch_size]\n",
    "            sess.run(train_disc, feed_dict={\n",
    "                X: xfeed, \n",
    "                Z: zfeed,\n",
    "                encoder_batch_trainable: False,\n",
    "                decoder_batch_trainable: False,\n",
    "                disc_batch_trainable: True\n",
    "            })\n",
    "            print('.', end='')\n",
    "\n",
    "    # train encoder\n",
    "    if do_train['encoder']:\n",
    "        for batch in range(batches):\n",
    "            xfeed = training[batch*batch_size:(batch+1)*batch_size]\n",
    "            sess.run(train_encoder, feed_dict={\n",
    "                X: xfeed,\n",
    "                encoder_batch_trainable: True,\n",
    "                decoder_batch_trainable: False,\n",
    "                disc_batch_trainable: False\n",
    "                })\n",
    "            print('.', end='')\n",
    "        \n",
    "    # train decoder\n",
    "    if do_train['decoder']:\n",
    "        for batch in range(batches):\n",
    "            xfeed = training[batch*batch_size:(batch+1)*batch_size]\n",
    "            zfeed = zdraws[batch*batch_size:(batch+1)*batch_size]\n",
    "            sess.run(train_decoder, feed_dict={\n",
    "                X: xfeed, \n",
    "                Z: zfeed,\n",
    "                encoder_batch_trainable: False,\n",
    "                decoder_batch_trainable: True,\n",
    "                disc_batch_trainable: False\n",
    "            })\n",
    "            print('.', end='')\n",
    "        \n",
    "    print('')\n",
    "    \n",
    "    if (epoch % 1 == 0):\n",
    "        print('saving session', flush=True)\n",
    "        saver.save(sess, model_save_path)\n",
    "        \n",
    "        xfeed = training[:batch_size]\n",
    "        zfeed = zdraws[:batch_size]\n",
    "        summary = merged_summary.eval(feed_dict={\n",
    "            X: xfeed, \n",
    "            Z: zfeed,\n",
    "            encoder_batch_trainable: False,\n",
    "            decoder_batch_trainable: False,\n",
    "            disc_batch_trainable: False\n",
    "        })\n",
    "        writer.add_summary(summary, epoch)\n",
    "                    \n",
    "        example = decoder.eval(feed_dict={\n",
    "            X: training[:1],\n",
    "            encoder_batch_trainable: False,\n",
    "            decoder_batch_trainable: False,\n",
    "            disc_batch_trainable: False\n",
    "        })\n",
    "        img_save_path = os.path.join(outputs_directory, '%06d.jpg' % img_idx)\n",
    "        img_idx += 1\n",
    "        sp.misc.imsave(img_save_path, pixels01(example[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
